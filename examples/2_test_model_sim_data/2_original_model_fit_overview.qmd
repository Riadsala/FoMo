---
title: "2) fitting the NEW  old foraging model - to simulated data"
author: "A D F Clarke & A Excellent Hughes"
format: html
editor: source
---

```{r, message=FALSE, warning = FALSE}
library(tidyverse)
library(cmdstanr)

source("../../functions/import_data.R")
source("../../functions/prep_data.R")
source("../../functions/compute_summary_stats.R")
source("../../functions/plot_model.R")
source("../../functions/plot_data.R")
source("../../functions/post_functions.R")
source("../../functions/sim_foraging_data.R")

options(mc.cores = 4)

# set global ggplot theme
theme_set(ggthemes::theme_tufte())
```

# Fitting Model to Simulated Data

- **Model 1.0**: the original model first detailed in Clarke et al (2022), reimplemented in new code. The only other edit is to correctly calculate absolute proximity (we previously scaled before calculating inter-item distances, which led to expansion of vertical distances compared to the horizontal in cases where foraging stimuli were arranged on a rectangular grid - this minor edit makes little difference to the overall fit of the model).
- **Model 1.1**: the same as model 1.1., except it uses relative proximity - for each item selection, we divide all inter-target distances by the distance to the closest item. The idea behind this is that it may allow the model's proximity weighting to cope better towards the end of a trial when the items are sparser.
- **Model 1.2**: here we add in (on top of 1.1? CHECK!) a component that allows for an absolute direction bias i.e. a bias for moving horizontally, or vertically.


## Example 1 - simple model with one participant

### First simulate some data

Our first simple simulation will involve 2 target classes, each with 20 items on screen. We will simulate one of the targets to be preferred over the other (`item_class_weights`), a small stick bias (`b_stick`), moderate proximity bias (`rho_delta`) and a fairly strong fowards momentum (`rho_psi`). 

Absolute direction tuning is only used from model 1.2 onwards: in this simulation, we are adding in a stronger bias for horizontal compared to vertical directions (is this true??)

This simple simulation only considers one participant, doing 10 trials of one condition.

```{r}

n_trials_per_cond <- 10

n_item_class <- 2
n_item_per_class <- 20
item_class_weights = c(0.7, 0.3, 0, 0)
b_stick = 2
b_memory = 0

abs_dir_tuning = list(kappa = rep(20, 4), theta = c(2, 0.5, 1, 0.5))
rho_delta = 10
rho_psi = 5

d1 <- sim_foraging_multiple_trials(person = 1, 
                                  condition = "test",
                                  n_item_class =  n_item_class, n_item_per_class = n_item_per_class,
                                  item_class_weights = item_class_weights, item_labels = item_labels,
                                  b_stick = b_stick, 
                                  rho_delta = rho_delta, 
                                  rho_psi = rho_psi, 
                                  abs_dir_tuning = abs_dir_tuning,
                                  b_memory = b_memory,
                                  inital_sel_params = inital_sel_params,
                                  init_sel_lambda = init_sel_lambda)


```

### Fitting model 1.0

Here, we fit model version 1.0.

```{r, message = FALSE, warning = FALSE, results = "hide"}

iter = 100
mod <- cmdstan_model("../../models/simple/FoMo1_0.stan", 
                     cpp_options = list(stan_threads = TRUE))

d1_list <- prep_data_for_stan(d1$found, d1$stim, c("spatial", "item_class"))

# add priors to list
d1_list$prior_mu_b_a <- 0
d1_list$prior_sd_b_a <- 0.5
d1_list$prior_mu_b_stick <- 0
d1_list$prior_sd_b_stick <- 1
d1_list$prior_mu_rho_delta <- 15
d1_list$prior_sd_rho_delta <- 5
d1_list$prior_mu_rho_psi <- 0
d1_list$prior_sd_rho_psi <- 1
d1_list$n_trials_to_sim <- 10

# run model
m <- mod$sample(data = d1_list, 
                  chains = 4, parallel_chains = 4, threads = 4,
                  refresh = 0, 
                  iter_warmup = iter, iter_sampling = iter,
                  sig_figs = 3)

```

### Extract posterior

We can then extract posterior samples.

```{r}

# extract post
post <- extract_post(m, d1, multi_level = FALSE)

```

### Plot model

We plot the fixed effects of the model (and can confirm that we are able to recover the parameters we put into the simulation).

```{r}

# plot model
plot_model_fixed(post, gt = list(b_a = plogis(item_class_weights[1]),
                                 b_stick = b_stick,
                                 rho_delta = rho_delta,
                                 rho_psi = rho_psi))

```

### Check predictions

We can assess model accuracy i.e. how well can it predict the next target chosen?

```{r}

pred <- summarise_postpred(m, d1)

plot_model_accuracy(pred)

```

### Plot comparison between a real and a simulated trial

And we can plot a comparison between a real and a simulated trial in order to visually inspect for obvious differences in the way the model is foraging compared to the simulated data.

```{r}

# plot comparison between a real and simulated trial

pltreal <- plot_a_trial(d1$stim, d1$found, 1)
pltsim <- plot_a_trial(d1$stim, pred$sim %>% filter(.draw == 1), trial = 1)

pltreal + pltsim


```

## Example 2 - multilevel model

### First simulate some data

We can build up our model to include multiple participants (5 in this case). Here, we again only consider one condition, but multiple conditions could be included (e.g. feature/conjunction). 

```{r simdata1, cache=TRUE}
item_class_weights = list(c(0.7, 0.3, 0, 0))

b_stick = 1

rho_delta = 15
sd_rho_delta = 5

rho_psi = -1

abs_dir_tuning = list(kappa = rep(10, 4), theta = rep(1, 4))

# initial bias params
inital_sel_params <- tibble(
  a1x = 2,
  b1x = 2,
  a2x = 1,
  b2x = 10,
  a1y = 2,
  b1y = 2,
  a2y = 10,
  b2y = 1) 

d2 <- sim_foraging_people(n_people = 5,
                    n_conditions = 1,
                    cond_lab = c("simple test"),
                    n_trials_per_cond = 4,
                    n_item_class = 2, n_item_per_class = 20,
                    item_class_weights, sd_bA = 0.2,
                    b_stick = b_stick, sd_b_stick = 1,
                    rho_delta = rho_delta, sd_rho_delta = sd_rho_delta,
                    rho_psi = rho_psi, sd_rho_psi = 0.5,
                    abs_dir_tuning = abs_dir_tuning,
                    inital_sel_params = inital_sel_params) 

d2$found <- fix_person_and_trial(d2$found)
d2$stim <- fix_person_and_trial(d2$stim)
```

### Now fit our model

We can use very similar code to fit model 1.0.

```{r prepsimdata1}
d2_list <- prep_data_for_stan(d2$found, d2$stim, c("spatial", "item_class"))
d2_list <- add_priors_to_d_list(d2_list)
```


```{r fitmodelsimdata1, eval = FALSE}
iter = 100
mod <- cmdstan_model("../../models/multi_level/FoMo1_0.stan", 
                     cpp_options = list(stan_threads = TRUE))

fit <- mod$sample(data = d2_list, 
                 chains = 4, parallel_chains = 4, threads = 4,
                 refresh = 10, 
                 iter_warmup = iter, iter_sampling = iter,
                 sig_figs = 3)

fit$save_object("scratch/multi_level_1_0_tmp.rds")

```

```{r}

fit <- readRDS("scratch/multi_level_1_0_tmp.rds")

```

### Posterior Density Plots

We can plot both fixed and random effects from the model.

```{r extractsim1post, cache=TRUE}
post <- extract_post(fit, d2)
```

#### Fixed Effects

```{r plotsim1fixed, fig.cap="fixed effects"}
plot_model_fixed(post, gt = list(b_a = plogis(item_class_weights[[1]][1]),
                                 b_stick = b_stick,
                                 rho_delta = rho_delta,
                                 rho_psi = rho_psi))
```

#### Random Effects

```{r plotsim1random, fig.cap="random effects"}
plot_model_random(post)
```


## Example 3 - fitting FoMo 1.1

The examples below use the same simple and multilevel simulations as in the previous example, but instead fit model version 1.1.

### The simple version

```{r, message = FALSE, warning = FALSE, results = "hide"}

iter = 100
item_class_weights = c(0.7, 0.3, 0, 0)
b_stick = 2
rho_delta = 10
rho_psi = 5

mod <- cmdstan_model("../../models/simple/FoMo1_1.stan", 
                     cpp_options = list(stan_threads = TRUE))
# run model
m <- mod$sample(data = d1_list, 
                  chains = 4, parallel_chains = 4, threads = 4,
                  refresh = 0, 
                  iter_warmup = iter, iter_sampling = iter,
                  sig_figs = 3)

```

```{r}

# extract post
post <- extract_post(m, d1, multi_level = FALSE)

```


```{r}

# plot model
plot_model_fixed(post, gt = list(b_a = plogis(item_class_weights[1]),
                                 b_stick = b_stick,
                                 rho_delta = rho_delta,
                                 rho_psi = rho_psi))

```


### The multilevel variant

```{r fitmodelsimdata1_1, eval = FALSE}
iter = 100
mod <- cmdstan_model("../../models/multi_level/FoMo1_1.stan", 
                     cpp_options = list(stan_threads = TRUE))

fit <- mod$sample(data = d2_list, 
                 chains = 4, parallel_chains = 4, threads = 4,
                 refresh = 10, 
                 iter_warmup = iter, iter_sampling = iter,
                 sig_figs = 3)

fit$save_object("scratch/multi_level_1_1_tmp.rds")

```


```{r}

fit <- readRDS("scratch/multi_level_1_1_tmp.rds")

```

### Posterior Density Plots

```{r extractsim1_1post, cache=TRUE}
post <- extract_post(fit, d2)
```

#### Fixed Effects

```{r plotsim1_1fixed, fig.cap="fixed effects"}

b_stick = 1
rho_delta = 15
rho_psi = -1

plot_model_fixed(post, gt = list(b_a = plogis(item_class_weights[[1]][1]),
                                 b_stick = b_stick,
                                 rho_delta = rho_delta,
                                 rho_psi = rho_psi))
```

#### Random Effects

```{r plotsim1_1random, fig.cap="random effects"}
plot_model_random(post)
```

## Comparing 1.1 and 1.0?


## Discussion

Hopefully we agree that the model fits well




